{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "128444fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS IS FOR USING JUST ONE GPU\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dab59ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/maria/anaconda3/envs/myenv/lib/python3.10/site-packages (4.51.3)\n",
      "Requirement already satisfied: datasets in /home/maria/anaconda3/envs/myenv/lib/python3.10/site-packages (3.5.0)\n",
      "Requirement already satisfied: evaluate in /home/maria/anaconda3/envs/myenv/lib/python3.10/site-packages (0.4.3)\n",
      "Requirement already satisfied: filelock in /home/maria/anaconda3/envs/myenv/lib/python3.10/site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /home/maria/anaconda3/envs/myenv/lib/python3.10/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/maria/anaconda3/envs/myenv/lib/python3.10/site-packages (from transformers) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/maria/anaconda3/envs/myenv/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/maria/anaconda3/envs/myenv/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/maria/anaconda3/envs/myenv/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/maria/anaconda3/envs/myenv/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/maria/anaconda3/envs/myenv/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/maria/anaconda3/envs/myenv/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/maria/anaconda3/envs/myenv/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/maria/anaconda3/envs/myenv/lib/python3.10/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/maria/anaconda3/envs/myenv/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/maria/anaconda3/envs/myenv/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /home/maria/anaconda3/envs/myenv/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/maria/anaconda3/envs/myenv/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /home/maria/anaconda3/envs/myenv/lib/python3.10/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in /home/maria/anaconda3/envs/myenv/lib/python3.10/site-packages (from datasets) (3.11.16)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/maria/anaconda3/envs/myenv/lib/python3.10/site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/maria/anaconda3/envs/myenv/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/maria/anaconda3/envs/myenv/lib/python3.10/site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/maria/anaconda3/envs/myenv/lib/python3.10/site-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/maria/anaconda3/envs/myenv/lib/python3.10/site-packages (from aiohttp->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/maria/anaconda3/envs/myenv/lib/python3.10/site-packages (from aiohttp->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/maria/anaconda3/envs/myenv/lib/python3.10/site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/maria/anaconda3/envs/myenv/lib/python3.10/site-packages (from aiohttp->datasets) (1.20.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/maria/anaconda3/envs/myenv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/maria/anaconda3/envs/myenv/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/maria/anaconda3/envs/myenv/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/maria/anaconda3/envs/myenv/lib/python3.10/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/maria/anaconda3/envs/myenv/lib/python3.10/site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/maria/anaconda3/envs/myenv/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/maria/anaconda3/envs/myenv/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/maria/anaconda3/envs/myenv/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/maria/anaconda3/envs/myenv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ba19b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maria/anaconda3/envs/myenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSM8K test set size: 1319 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating base Phi model (zero-shot)...:   0%|          | 1/1319 [00:00<18:58,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First Example:\n",
      "Question: Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\n",
      "Expected (gold): 18\n",
      "Predicted: 224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating base Phi model (zero-shot)...: 100%|██████████| 1319/1319 [17:31<00:00,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Correct predictions: 48/1319\n",
      "Accuracy of base Phi model (zero-shot): 3.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the tokenizer and the base Phi model (not fine-tuned)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-1_5\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-1_5\")\n",
    "\n",
    "# Set the model to evaluation mode and move it to GPU if available\n",
    "model.eval().to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the official GSM8K test set (1,319 examples)\n",
    "gsm8k = load_dataset(\"gsm8k\", \"main\", split=\"test\")\n",
    "\n",
    "# Print how many test examples are being evaluated\n",
    "print(f\"GSM8K test set size: {len(gsm8k)} examples\")\n",
    "\n",
    "# Initialize counter for correct predictions\n",
    "correct = 0\n",
    "\n",
    "# Boolean flag to track whether we’ve printed the first example\n",
    "first_printed = False\n",
    "\n",
    "# Loop through each example in the dataset\n",
    "for item in tqdm(gsm8k, desc=\"Evaluating base Phi model (zero-shot)...\"):\n",
    "    \n",
    "    # Extract the question and strip any whitespace\n",
    "    question = item[\"question\"].strip()\n",
    "\n",
    "    # Use regular expressions to extract numbers from the gold answer\n",
    "    # Take the last number found as the final numeric answer\n",
    "    gold_answer = re.findall(r\"\\d+\", item[\"answer\"])\n",
    "    gold = gold_answer[-1] if gold_answer else None\n",
    "\n",
    "    # Build the zero-shot prompt (no examples, no reasoning, just the question)\n",
    "    prompt = question + \"\\nA:\"\n",
    "    \n",
    "    # Tokenize the prompt and move it to the model's device (CPU or GPU)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    # Use the model to generate a prediction, limiting the output length\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=50)\n",
    "        decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Extract any numbers from the model’s output\n",
    "    # Take the last number found as the model's predicted answer\n",
    "    pred_numbers = re.findall(r\"\\d+\", decoded)\n",
    "    prediction = pred_numbers[-1] if pred_numbers else None\n",
    "\n",
    "    # For the first example only, print the full comparison\n",
    "    if not first_printed:\n",
    "        print(\"\\nFirst Example:\")\n",
    "        print(f\"Question: {question}\")\n",
    "        print(f\"Expected (gold): {gold}\")\n",
    "        print(f\"Predicted: {prediction}\")\n",
    "        first_printed = True\n",
    "\n",
    "    # Count the prediction as correct if it matches the gold answer\n",
    "    if prediction == gold:\n",
    "        correct += 1\n",
    "\n",
    "# After all predictions, calculate and print the accuracy\n",
    "total = len(gsm8k)\n",
    "accuracy = correct / total * 100\n",
    "print(f\"\\nCorrect predictions: {correct}/{total}\")\n",
    "print(f\"Accuracy of base Phi model (zero-shot): {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52066cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
